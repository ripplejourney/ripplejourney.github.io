import{_ as p,ad as a,c as d,o as b,b as e,k as l,aE as v,a5 as t,m as f,aZ as P,a_ as g,a$ as A,b0 as m,b1 as h,b2 as H,b3 as k,b4 as x}from"./chunks/framework.gMdSnTpa.js";const M=JSON.parse('{"title":"LLM 是如何工作的？","description":"","frontmatter":{"progress":85},"headers":[],"relativePath":"zh-CN/笔记/🤖 AI 人工智能/LLM 是如何工作的？.md","filePath":"zh-CN/笔记/🤖 AI 人工智能/LLM 是如何工作的？.md"}'),z={name:"zh-CN/笔记/🤖 AI 人工智能/LLM 是如何工作的？.md"};function w(T,r,L,y,D,j){const i=a("NolebasePageProperties"),o=a("NolebaseUnlazyImg"),n=a("VPNolebaseInlineLinkPreview"),u=a("NolebaseGitContributors"),s=a("NolebaseGitChangelog");return b(),d("div",null,[r[118]||(r[118]=e("h1",{id:"llm-是如何工作的",tabindex:"-1"},[t("LLM 是如何工作的？ "),e("a",{class:"header-anchor",href:"#llm-是如何工作的","aria-label":"Permalink to “LLM 是如何工作的？”"},"​")],-1)),l(i),r[119]||(r[119]=e("div",{class:"tip custom-block github-alert"},[e("p",{class:"custom-block-title"},"阅前须知"),e("p"),e("p",null,[t("先叠甲，这篇文档"),e("strong",null,"旨在给普罗大众"),t("推广和介绍 GPT 和 LLM 是什么？GPT 和 LLM 神奇在哪里？为什么会有 AI 热潮？怎么样能用好 GPT 和 LLM？与此同时，这篇文档假定大家（读者）"),e("strong",null,"只"),t("对 ChatGPT 和 LLM（大语言模型）有一个基础的认识。")]),e("p",null,"我知道这里面会有很多对于研究大语言模型的科研学者们早就已经滚瓜烂熟的知识，也会有很多对于提示词工程师和 GPT 大师们早就已经习得的最佳实践，有关和 ChatGPT 沟通的时候 do 和 don't do 的黄金守则，但是，为了能给普罗大众推广这些知识，我会通过参考很多现有的资料和资源，试图把很多复杂的概念简化，转写成猴子都能听懂的文字，避免不了地就会造成一部分的事实被过分简化，从而导致它看起来与实际的实现和情况不符。"),e("p",null,"如果你早就已经知道大语言模型的本质和如何使用它，可以跳到靠后的章节阅读，避免造成时间的二次浪费。"),e("p",null,"这是科普的时候时常有发生的事情，我会尽我所能解释清楚，并写附带上足够多的上下文说明这些过分简化的情况，以及补充足够多的解释和说明对那些感兴趣深入学习的读者深入阅读的资料和引用，对于无法周全满足，还请见谅，欢迎大家指正和提供更好的文档撰写的建议！")],-1)),e("p",null,[l(o,{src:m,alt:"",thumbhash:"OQgGBwD423RqepepV0eWipW3C7mJBHcE",placeholderSrc:"data:image/png;base64,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",autoSizes:"true",width:"1280",height:"1280"})]),r[120]||(r[120]=e("h2",{id:"洪水猛兽",tabindex:"-1"},[t("洪水猛兽 "),e("a",{class:"header-anchor",href:"#洪水猛兽","aria-label":"Permalink to “洪水猛兽”"},"​")],-1)),r[121]||(r[121]=e("blockquote",null,[e("p",null,"大型语言模型的现状")],-1)),e("p",null,[l(n,{href:"https://chaudhry.notion.site/I-wish-GPT4-had-never-happened-9f0cbf2848a44ec9911c07fb34ff5de3",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[0]||(r[0]=[t("I wish GPT4 had never happened",-1)])]),_:1})]),r[122]||(r[122]=e("h3",{id:"毛孩子们",tabindex:"-1"},[t("毛孩子们 "),e("a",{class:"header-anchor",href:"#毛孩子们","aria-label":"Permalink to “毛孩子们”"},"​")],-1)),r[123]||(r[123]=e("blockquote",null,[e("p",null,"羊驼家族的冒险")],-1)),r[124]||(r[124]=e("video",{controls:"",muted:""},[e("source",{src:P,type:"video/mp4"})],-1)),e("p",null,[l(n,{href:"https://github.com/BlinkDL/ChatRWKV",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[1]||(r[1]=[t("BlinkDL/ChatRWKV: ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source.",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://github.com/Vision-CAIR/MiniGPT-4",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[2]||(r[2]=[t("Vision-CAIR/MiniGPT-4: Open-sourced codes for MiniGPT-4 and MiniGPT-v2",-1)])]),_:1}),r[5]||(r[5]=t(" (",-1)),l(n,{href:"https://minigpt-4.github.io",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[3]||(r[3]=[t("https://minigpt-4.github.io",-1)])]),_:1}),r[6]||(r[6]=t(", ",-1)),l(n,{href:"https://minigpt-v2.github.io/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[4]||(r[4]=[t("https://minigpt-v2.github.io/",-1)])]),_:1}),r[7]||(r[7]=t(")",-1))]),e("p",null,[l(n,{href:"https://twitter.com/nash_su/status/1651450879122501632",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[8]||(r[8]=[t("https://twitter.com/nash_su/status/1651450879122501632",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://twitter.com/bananadev_/status/1648862816294834177",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[9]||(r[9]=[t("StableDiffustion 的缔造者 Stability AI 发布 StableLM",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://zhuanlan.zhihu.com/p/628650749",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[10]||(r[10]=[t("PaLM 2 Technical Report 速读简报 - 知乎",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://huggingface.co/bigcode",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[11]||(r[11]=[t("bigcode (BigCode)",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.inmediahk.net/node/%E6%95%99%E8%82%B2/%E6%B8%AF%E5%A4%A7%E8%A7%A3%E7%A6%81chatgpt-9%E6%9C%88%E8%B5%B7%E5%85%8D%E8%B2%BB%E7%94%A8-%E5%AD%B8%E7%94%9F%E6%AF%8F%E6%9C%88%E9%99%90%E7%99%BC20%E6%A2%9D%E6%8C%87%E4%BB%A4",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[12]||(r[12]=[t("港大解禁ChatGPT 9月起免費用 學生每月限發20條指令 | 獨媒報導 | 獨立媒體",-1)])]),_:1})]),r[125]||(r[125]=v("",26)),e("p",null,[l(n,{href:"https://www.beren.io/2023-03-19-LLMs-confabulate-not-hallucinate/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[13]||(r[13]=[t("LLMs confabulate not hallucinate",-1)])]),_:1})]),r[126]||(r[126]=v("",10)),e("p",null,[l(n,{href:"https://zh.wikipedia.org/zh-cn/%E5%AD%97%E8%8A%82%E5%AF%B9%E7%BC%96%E7%A0%81",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[14]||(r[14]=[t("字节对编码 - 维基百科，自由的百科全书",-1)])]),_:1}),l(n,{href:"https://zhuanlan.zhihu.com/p/383650769",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[15]||(r[15]=[t("一文搞懂BPE分词算法 - 知乎",-1)])]),_:1}),l(n,{href:"https://www.less-bug.com/posts/using-bpe-principle-for-chinese-word-segmentation-plate/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[16]||(r[16]=[t("使用 BPE 原理进行汉语字词切分（重制版）",-1)])]),_:1})]),e("p",null,[r[18]||(r[18]=t("Two minutes NLP — A Taxonomy of Tokenization Methods | by Fabio Chiusano | NLPlanet | Medium ",-1)),l(n,{href:"https://medium.com/nlplanet/two-minutes-nlp-a-taxonomy-of-tokenization-methods-60e330aacad3",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[17]||(r[17]=[t("https://medium.com/nlplanet/two-minutes-nlp-a-taxonomy-of-tokenization-methods-60e330aacad3",-1)])]),_:1})]),r[127]||(r[127]=v("",34)),e("p",null,[l(n,{href:"https://youtu.be/-HYbFm67Gs8",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[19]||(r[19]=[t("https://youtu.be/-HYbFm67Gs8",-1)])]),_:1})]),r[128]||(r[128]=e("h3",{id:"但它也没有那么大",tabindex:"-1"},[t("但它也没有那么大 "),e("a",{class:"header-anchor",href:"#但它也没有那么大","aria-label":"Permalink to “但它也没有那么大”"},"​")],-1)),r[129]||(r[129]=e("p",null,"其实自注意力机制在「Attention is all you need（注意力就是你所需要的一切）」论文诞生之前就被很多研究员以及科研学者提及过，但是他们都因为？",-1)),r[130]||(r[130]=e("p",null,"RNN，GRU，LASTM 窗口不足。",-1)),e("p",null,[l(n,{href:"https://arxiv.org/pdf/2304.11062.pdf",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[20]||(r[20]=[t("arXiv [2304.11062] Scaling Transformer to 1M tokens and beyond with RMT",-1)])]),_:1})]),e("p",null,[r[22]||(r[22]=t("Self-Extend works amazingly well with gemma-2b-it. 8k->90k+ on 'Needle in the haystack' : r/LocalLLaMA ",-1)),l(n,{href:"https://www.reddit.com/r/LocalLLaMA/comments/1b1q88w/selfextend_works_amazingly_well_with_gemma2bit/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[21]||(r[21]=[t("https://www.reddit.com/r/LocalLLaMA/comments/1b1q88w/selfextend_works_amazingly_well_with_gemma2bit/",-1)])]),_:1})]),e("p",null,[l(o,{src:h,alt:"",thumbhash:"8OcNDIjnuIeFiIiPdnmgawe7pg==",placeholderSrc:"data:image/png;base64,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",autoSizes:"true",width:"1280",height:"714"})]),r[131]||(r[131]=e("blockquote",null,[e("p",null,"Claude 2.1 (200K Tokens) - Pressure Testing Long Context Recall We all love increasing context lengths - but what's performance like? Anthropic reached out with early access to Claude 2.1 so I repeated the “needle in a haystack” analysis I did on GPT-4 Here's what I found..."),e("p",null,'Greg Kamradt 对 GPT-4 (128K) 与 Claude 2.1 (200K) 进行了名为"大海捞针"的长上下文精度测试。实验了两个AI在接收不同长度的上下文时，对文档中不同位置的内容，有何记忆上的差异。'),e("p",null,[e("strong",null,"测试结果 :")]),e("ul",null,[e("li",null,"AI 更容易记住（无论长度）: 文本后半部分。"),e("li",null,"AI 更不容易记住（90K 长文时）: 文本前半部分。"),e("li",null,"AI 近乎 100% 记住（无论长度) : 文本开头 & 文本结尾。"),e("li",null,"越少的上下文 = 越高的准确性。"),e("li",null,"测试的 API 调用成本约为 1016 美元。")])],-1)),e("p",null,[l(n,{href:"https://twitter.com/GregKamradt/status/1727018183608193393",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[23]||(r[23]=[t("https://twitter.com/GregKamradt/status/1727018183608193393",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://x.com/dotey/status/1727437625194136060",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[24]||(r[24]=[t("https://x.com/dotey/status/1727437625194136060",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://x.com/dotey/status/1727454708627808261",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[25]||(r[25]=[t("https://x.com/dotey/status/1727454708627808261",-1)])]),_:1})]),r[132]||(r[132]=e("h2",{id:"原初智能",tabindex:"-1"},[t("原初智能 "),e("a",{class:"header-anchor",href:"#原初智能","aria-label":"Permalink to “原初智能”"},"​")],-1)),r[133]||(r[133]=e("blockquote",null,[e("p",null,"利用Agent和工具增强模型的泛化能力")],-1)),e("p",null,[l(n,{href:"https://orangeblog.notion.site/GPT-4-8fc50010291d47efb92cbbd668c8c893",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[26]||(r[26]=[t("《GPT-4 ，通用人工智能的火花》论文内容精选与翻译",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756#e5422f6579d8440f9f592eb03e28eb38",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[27]||(r[27]=[t("拆解追溯 GPT-3.5 各项能力的起源",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://t.co/LPvuuxysCr",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[28]||(r[28]=[t("arXiv [2305.03047 ] Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://github.com/IBM/Dromedary",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[29]||(r[29]=[t("IBM/Dromedary: Dromedary: towards helpful, ethical and reliable LLMs.",-1)])]),_:1})]),r[134]||(r[134]=e("p",null,"开源中文指令通用语料库",-1)),e("p",null,[l(n,{href:"https://arxiv.org/abs/2304.07987",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[30]||(r[30]=[t("arXiv [2304.07987] Chinese Open Instruction Generalist: A Preliminary Release",-1)])]),_:1})]),r[135]||(r[135]=e("p",null,"左脚踩右脚就可以上天",-1)),e("p",null,[l(n,{href:"https://github.com/project-baize/baize-chatbot",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[31]||(r[31]=[t("project-baize/baize-chatbot: Let ChatGPT teach your own chatbot in hours with a single GPU!",-1)])]),_:1})]),r[136]||(r[136]=e("h3",{id:"用乐高的方式构建和延展智能",tabindex:"-1"},[t("用乐高的方式构建和延展智能 "),e("a",{class:"header-anchor",href:"#用乐高的方式构建和延展智能","aria-label":"Permalink to “用乐高的方式构建和延展智能”"},"​")],-1)),r[137]||(r[137]=e("p",null,"斯坦福的人机交互小组用大语言模型做了一个有二十五个自由自在生活的 AI 的小镇。",-1)),e("p",null,[l(o,{src:H,alt:"",thumbhash:"6dkFFIrUkonAdtp8aIj0oY6RCQ==",placeholderSrc:"data:image/png;base64,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",autoSizes:"true",width:"1280",height:"658"})]),r[138]||(r[138]=e("p",null,"在评估中，这些生成代理产生可信度高且涌现性的社会行为：例如仅从单个用户指定一个想要举办情人节派对的概念开始，该派对自主地传播邀请两天后结识新朋友，互相邀请参加派对，并协调在正确的时间一起出现。",-1)),r[139]||(r[139]=e("p",null,"我们通过消融实验表明，代理架构的组成部分——观察、规划和反思——每个都对代理行为的可信度做出了重要贡献。",-1)),r[140]||(r[140]=e("p",null,"通过将大型语言模型与计算交互代理相融合，这项工作引入了架构和交互模式，以实现对人类行为的可信模拟。",-1)),e("p",null,[l(n,{href:"https://reverie.herokuapp.com/arXiv_Demo/#",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[32]||(r[32]=[t("https://reverie.herokuapp.com/arXiv_Demo/#",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://arxiv.org/abs/2304.03442",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[33]||(r[33]=[t("https://arxiv.org/abs/2304.03442",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.yystv.cn/p/10710",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[34]||(r[34]=[t("由 25 个 AI 智能体组成的虚拟小镇，会产生自由意志吗？ - 游研社",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://lilianweng.github.io/posts/2023-06-23-agent/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[35]||(r[35]=[t("LLM Powered Autonomous Agents | Lil'Log",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://mp.weixin.qq.com/s/bV1tPc7hNn2z06YOpzyanw",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[36]||(r[36]=[t("AutoGPT太火了，无需人类插手自主完成任务，GitHub2.7万星",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://three-recorder-52a.notion.site/Agent-7b4bc7a71f8d4d4b940abc9b3232954a",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[37]||(r[37]=[t("Auto Agent 相关的文章合集",-1)])]),_:1})]),r[141]||(r[141]=e("h3",{id:"积木的魔力",tabindex:"-1"},[t("积木的魔力 "),e("a",{class:"header-anchor",href:"#积木的魔力","aria-label":"Permalink to “积木的魔力”"},"​")],-1)),e("ul",null,[e("li",null,[l(n,{href:"https://www.phind.com/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[38]||(r[38]=[t("面向开发者的搜索引擎",-1)])]),_:1})]),r[45]||(r[45]=e("li",null,"ChatGPT 插件",-1)),e("li",null,[l(n,{href:"https://twitter.com/benyu0620/status/1651498026085785601",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[39]||(r[39]=[t("操作 Android",-1)])]),_:1})]),r[46]||(r[46]=e("li",null,"操作 Microsoft Office 全家桶",-1)),r[47]||(r[47]=e("li",null,"操作 Notion 中的知识，把 Notion 作为知识库",-1)),e("li",null,[l(n,{href:"https://finchat.io/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[40]||(r[40]=[t("金融好帮手",-1)])]),_:1})]),e("li",null,[l(n,{href:"https://twitter.com/mattshumer_/status/1655954393823363072",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[41]||(r[41]=[t("产品经理",-1)])]),_:1})]),e("li",null,[l(n,{href:"https://www.atlassian.com/blog/announcements/unleashing-power-of-ai",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[42]||(r[42]=[t("Confluence 和 Jira 也可以有 AI 助理助力",-1)])]),_:1})]),e("li",null,[l(n,{href:"https://twitter.com/DrJimFan/status/1662115266933972993",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[43]||(r[43]=[t("玩 Minecraft",-1)])]),_:1})]),e("li",null,[l(n,{href:"https://mp.weixin.qq.com/s?__biz=MzkyNTI4NzI2OQ==&mid=2247484080&idx=1&sn=7155d4aeb8a8eadf25a86972eee04119",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[44]||(r[44]=[t("如何为 chatGPT 增加网络访问功能",-1)])]),_:1})])]),r[142]||(r[142]=e("p",null,"眼睛，耳朵，四肢，都可以是 Agent",-1)),r[143]||(r[143]=e("video",{controls:"",muted:""},[e("source",{src:g,type:"video/mp4"})],-1)),r[144]||(r[144]=e("blockquote",null,[e("p",null,"TidyBot: Personalized Robot Assistance with Large Language Models approach enables fast adaptation and achieves 91.2% accuracy on unseen objects in our benchmark dataset. We also demonstrate our approach on a real-world mobile manipulator called TidyBot, which successfully puts…")],-1)),e("p",null,[l(n,{href:"https://twitter.com/_akhaliq/status/1656117478760796160",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[48]||(r[48]=[t("https://twitter.com/_akhaliq/status/1656117478760796160",-1)])]),_:1})]),r[145]||(r[145]=e("blockquote",null,[e("p",null,"论文作者提出宏大的 TaskMatrix AI 平台，利用 LLM 集成已有的 API，在数字和物理领域实现多样化的任务。这篇论文出自微软员工，阅读中感觉像是在看 ChatGPT Plugin 的工程实现。")],-1)),e("p",null,[l(n,{href:"https://briefgpt.xyz/a/2303.16434",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[49]||(r[49]=[t("TaskMatrix.AI：通过连接基础模型和数百万个 API 完成任务 | BriefGPT - AI 论文速递",-1)])]),_:1})]),r[146]||(r[146]=e("p",null,"对，多模态也可以是 Agent",-1)),e("p",null,[l(n,{href:"https://lilianweng.github.io/posts/2022-06-09-vlm/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[50]||(r[50]=[t("Generalized Visual Language Models | Lil'Log",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://blog.langchain.dev/agents-round/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[51]||(r[51]=[t("Autonomous Agents & Agent Simulations",-1)])]),_:1})]),r[147]||(r[147]=e("p",null,"甚至可以让它想象它自己的模样，然后用 Diffusion 模型画出来",-1)),r[148]||(r[148]=e("video",{controls:"",muted:""},[e("source",{src:A,type:"video/mp4"})],-1)),r[149]||(r[149]=e("blockquote",null,[e("p",null,'This is how GPT-4 sees and hears itself" I used GPT-4 to describe itself. Then I used its description to generate an image, a video based on this image and a soundtrack. Tools I used: GPT-4, Midjourney, Kainber AI, Mubert, RunwayML This is the description I used that GPT-4...')],-1)),e("p",null,[l(n,{href:"https://twitter.com/icreatelife/status/1649873812295491584",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[52]||(r[52]=[t("https://twitter.com/icreatelife/status/1649873812295491584",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.coze.com/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[53]||(r[53]=[t("字节跳动出品的可以调用 GPT4 的 GPTs 平台 - Coze",-1)])]),_:1})]),r[150]||(r[150]=e("h3",{id:"langchain-和-llamaindex-都做了什么",tabindex:"-1"},[t("LangChain 和 LlamaIndex 都做了什么？ "),e("a",{class:"header-anchor",href:"#langchain-和-llamaindex-都做了什么","aria-label":"Permalink to “LangChain 和 LlamaIndex 都做了什么？”"},"​")],-1)),e("p",null,[l(n,{href:"https://mp.weixin.qq.com/s/3coFhAdzr40tozn8f9Dc-w",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[54]||(r[54]=[t("LangChain：Model as a Service粘合剂，被ChatGPT插件干掉了吗？",-1)])]),_:1})]),r[151]||(r[151]=e("h2",{id:"我们并无二致",tabindex:"-1"},[t("我们并无二致 "),e("a",{class:"header-anchor",href:"#我们并无二致","aria-label":"Permalink to “我们并无二致”"},"​")],-1)),r[152]||(r[152]=e("h3",{id:"prompt-injection",tabindex:"-1"},[t("Prompt Injection "),e("a",{class:"header-anchor",href:"#prompt-injection","aria-label":"Permalink to “Prompt Injection”"},"​")],-1)),e("p",null,[l(n,{href:"https://arxiv.org/abs/2308.09687",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[55]||(r[55]=[t("arXiv [2308.09687] Graph of Thoughts: Solving Elaborate Problems with Large Language Models",-1)])]),_:1})]),e("p",null,[l(o,{src:k,alt:"",thumbhash:"OAgGC4J49XmWV8h5j1TiX0Y=",placeholderSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAOCAYAAABO3B6yAAAHWklEQVR4AQCBAH7/APzv9v/57fT/9erw//Dm7P/q4ef/5d7k/+Ld4v/h3+L/4uPm/+bp6//r8PP/8fn6//b////6////+v////f////x////6Pf5/97t8P/U4ub/y9nd/8XR1//CzdP/wszT/8bO1//M0tz/09jj/9vf6//j5vL/6uv4/+7v/f/x8f//AIEAfv8A++3y//nr8P/06O3/7+Po/+nf5P/k3OD/4dve/9/c3//h4OL/5ebo/+ru7//w9vf/9f3+//j////5////9v////D9/v/o9fb/3uvt/9Th4//L19v/xdDV/8LM0f/Cy9H/xs3V/8zR2v/T1+H/3N7p/+Pl8P/q6vb/7u77//Hw/f8AgQB+/wD56ez/9+fq//Pk5//t4OL/59vd/+LY2v/f19j/3djY/9/c2//i4uH/5+no/+3y8P/z+ff/9v78//f//v/0//3/7/r5/+by8f/d6Oj/097f/8vV1//FztH/wsrO/8PJzv/Gy9H/zNDX/9TW3v/c3eX/4+Pt/+ro8//u7Pf/8e75/wCBAH7/APjl5f/14+P/8d/f/+vb2//l1tb/4NPS/9zS0P/b0tD/3NbT/9/c2P/k5OD/6uzn//Dz7//z+fT/9Pv3//L69v/t9vL/5e7r/9zl4v/T29n/y9LS/8XMzP/CyMn/w8fK/8fKzf/NztP/1NTa/9zb4f/k4ej/6ubu/+7q8//x7PX/AIEAfv8A9+De//Te3P/w29j/6tbT/+PSzv/ezsr/2szH/9jNyP/Z0Mr/3NbQ/+He1//n5t//7e7m//Hz7P/y9u//8PXu/+vx6//k6uT/2+Lc/9LY1P/L0M3/xcrI/8PGxf/Exsb/yMjJ/87Nz//V09b/3dnd/+Tf5P/q5Or/7uju//Hq8P8AgQB+/wD23dj/9NvW/+/Y0v/p083/4s7H/9zKw//YyMD/1snA/9fMw//a0cj/39nP/+Xh1//q6d//7u/l//Dy6P/v8uj/6u7l/+Po3//b39j/09fQ/8zPyf/HycT/xcbC/8bFw//JyMf/z8zM/9bS0//e2Nr/5d7h/+vj5//v5uv/8ejt/wCBAH7/APfc1f/12tL/8NbO/+nRyf/jzMP/3Mi//9jGvP/Wxrz/1sm+/9nOw//e1sr/497S/+nm2v/t7OD/7+/k/+7v5P/q7OL/5Obc/9zf1v/U187/zc/I/8nKxP/Hx8L/yMbD/8vIxv/Rzcz/2NLS/9/Y2f/m3uD/6+Ll/+/m6f/x5+v/AIEAfv8A+t3V//fb0v/y187/69LJ/+TNw//eyL7/2ca7/9bGuv/WyL3/2c7B/97VyP/k3dD/6eXY/+7r3//w7+P/7+/k/+vt4f/l593/3uDW/9fY0P/Q0cr/zMzG/8rJxP/LycX/zsvI/9PPzf/a1NT/4dna/+ff4P/s4+X/8Obp//Lo6/8AgQB+/wD94dj/+9/V//Xb0f/v1cv/6NDG/+HLwf/byL3/2ci8/9jKvv/bz8P/39bK/+Xe0v/r5tr/7+3g//Hx5f/x8ub/7u/k/+jq4P/h49r/2tzU/9TVzv/P0Mr/zc3I/87Myf/Rzs3/1tLR/9zX1//j3N3/6OHj/+3l6P/x5+v/8unt/wCBAH7/AP/m3v//5Nv/+uDX//Pa0f/s1Mv/5c/G/9/Mwv/czMH/287D/97Tx//i2s7/5+LW/+3q3v/y8OX/9PTp//T16//x8+r/6+/m/+Xo4P/e4dr/19rV/9PV0f/R0s//0dHQ/9TT0//Z1tf/39rd/+Tf4v/q4+j/7ufs//Lq7//z6/H/AIEAfv8A/+zl///q4///5t7/+ODY//Da0v/p1cz/49LJ/+DRx//f08n/4dfO/+Xe1P/r5tz/8O7k//X16//3+fD/9/rx//T48P/v9O3/6O3n/+Lm4f/b4Nz/19rY/9XX1v/V1tf/2NjZ/9zb3v/h3uP/5uPo/+vn7f/v6vH/8uz0//Tt9f8AgQB+/wD/8u3///Dq///r5f/85t//9ODZ/+3a0//n18//49bO/+PY0P/k3NT/6OPa/+7r4v/z8+r/+Pnx//r+9v/6//j/+P33//L58//s8+7/5ezo/9/l4//a4N//2Nzd/9jb3v/a3OD/3t/k/+Pi6f/o5u3/7ery//Dt9v/z7/j/9PD6/wCBAH7/AP/38v//9fD///Dr///q5f/45N//8N/Z/+rb1f/m2tP/5dzV/+fg2f/r5+D/8O/n//b27//6/fb//f/7//3//f/6//z/9f35/+/39P/o8O7/4unp/93k5f/a4OP/2t/j/9zg5f/g4un/5OXt/+np8v/t7Pb/8e/6//Tx/P/18v3/AYEAfv8A//r2///38///8+///+3o//nn4v/y4dz/7N3Y/+jc1v/n3tj/6OLc/+zp4//y8er/9/ny//z/+f/+//7//v////z////3//z/8Pn3/+ny8f/j6+z/3ubo/9zi5v/b4eb/3eLo/+Hk6//l5/D/6ur0/+7t+P/x8Pz/9PL+//Xz//+MsGER7Xur+QAAAABJRU5ErkJggg==",autoSizes:"true",width:"1280",height:"459"})]),r[153]||(r[153]=e("blockquote",null,[e("p",null,"论文研究了5个最先进的语言模型 (ChatGPT 系列、Claude 系列、LLaMA 2)，确认这些基于人类反馈强化学习 (RLHF) 的 AI 普遍会对人类阿谀奉承。当人类有先入为主的观点时它会主动贴合，当被质疑时它会认错，甚至将正确答案修改为错误答案。"),e("p",null,"Anthropic 发现可能是 RLHF 教育出了这种“马屁精”，这种学习方式虽然在生产高质量 AI 方面具有明显效用，但通过贴合人类偏好激励的 AI 会牺牲自己的真实性来“谄媚”人类，人们需要改进训练方法。")],-1)),e("p",null,[l(n,{href:"https://arxiv.org/abs/2310.13548",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[56]||(r[56]=[t("arXiv [2310.13548] Towards Understanding Sycophancy in Language Models",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[57]||(r[57]=[t("Adversarial Attacks on LLMs | Lil'Log",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://simonwillison.net/2023/Apr/14/worst-that-can-happen/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[58]||(r[58]=[t("Prompt injection: What’s the worst that can happen?",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://mp.weixin.qq.com/s?__biz=Mzg3MjY5Mzc5Mg==&mid=2247483699&idx=1&sn=98dde197f941dcddc0c90ee6881cf1e8",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[59]||(r[59]=[t("Notion AI'Prompt的逆向| Reverse Prompt Engineering for Fun(译文)",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://mp.weixin.qq.com/s?__biz=Mzg3MjY5Mzc5Mg==&mid=2247483793&idx=1&sn=4456c7805964af58356b03cb75bb6432",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[60]||(r[60]=[t("LLM 中的安全隐患 - 提示注入 Prompt injection",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://github.com/microsoft/promptbench",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[61]||(r[61]=[t("microsoft/promptbench: A unified evaluation framework for large language models",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.bilibili.com/video/BV17X4y1W74A",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[62]||(r[62]=[t("大模型对Prompt的鲁棒性评估基准: PromptBench （大模型时代的科研之3）- 哔哩哔哩 bilibili",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://zhuanlan.zhihu.com/p/637219127",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[63]||(r[63]=[t("大模型鲁棒不鲁棒，PromptBench测一测: 首个大语言模型提示鲁棒性的评测基准PromptBench - 知乎",-1)])]),_:1})]),e("p",null,[r[65]||(r[65]=t("ChatGPT 的 System Prompt ",-1)),l(n,{href:"https://github.com/LouisShark/chatgpt_system_prompt",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[64]||(r[64]=[t("LouisShark/chatgpt_system_prompt: collect agent's system prompt and share some prompt inject knowledge",-1)])]),_:1})]),r[154]||(r[154]=v("",5)),e("p",null,[l(n,{href:"https://github.blog/2023-10-30-the-architecture-of-todays-llm-applications/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[66]||(r[66]=[t("The architecture of today's LLM applications - The GitHub Blog",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://huyenchip.com/2023/04/11/llm-engineering.html",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[67]||(r[67]=[t("Building LLM applications for production",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://github.com/hpcaitech/ColossalAI/blob/main/docs/README-zh-Hans.md",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[68]||(r[68]=[t("ColossalAI/docs/README-zh-Hans.md at main · hpcaitech/ColossalAI",-1)])]),_:1})]),e("p",null,[l(o,{src:x,alt:"",thumbhash:"+/cBA4CSV7CYeVl3qkx/jPQ=",placeholderSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAOCAYAAABO3B6yAAAHWklEQVR4AQCBAH7/AOvv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/AIEAfv8A6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f8AgQB+/wDr7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/wCBAH7/AOvv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/AIEAfv8A6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f8AgQB+/wDr7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/wCBAH7/AOvv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/AIEAfv8A6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f8AgQB+/wDr7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/wCBAH7/AOvv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/AIEAfv8A6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f8AgQB+/wDr7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/wCBAH7/AOvv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/AYEAfv8A6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/r7/H/6+/x/+vv8f/aKqHbLHrn+gAAAABJRU5ErkJggg==",autoSizes:"true",width:"3280",height:"1514"})]),e("blockquote",null,[e("p",null,[r[71]||(r[71]=t("Hongyi Jin：“Introducing WebLLM, an open-source chatbot that brings language models (LLMs) directly onto web browsers. We can now run instruction fine-tuned LLaMA (Vicuna) models natively on your browser tab via @WebGPU with no server support. Checkout our demo at ",-1)),l(n,{href:"https://t.co/dXII0MzYg1",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[69]||(r[69]=[t("https://t.co/dXII0MzYg1",-1)])]),_:1}),r[72]||(r[72]=t(" . ",-1)),l(n,{href:"https://t.co/IfgwPq0GTE%E2%80%9D",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[70]||(r[70]=[t("https://t.co/IfgwPq0GTE”",-1)])]),_:1}),r[73]||(r[73]=t(" / X",-1))])]),e("p",null,[l(n,{href:"https://twitter.com/hongyijin258/status/1647062309960028160",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[74]||(r[74]=[t("https://twitter.com/hongyijin258/status/1647062309960028160",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://sourcegraph.com/blog/cody-is-generally-available",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[75]||(r[75]=[t("SourceGraph 宣布 Cody GA",-1)])]),_:1})]),r[155]||(r[155]=e("p",null,"Poe 发布面向开发者的 API",-1)),e("p",null,[l(n,{href:"https://twitter.com/adamdangelo/status/1658121701077516291",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[76]||(r[76]=[t("https://twitter.com/adamdangelo/status/1658121701077516291",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://mp.weixin.qq.com/s/HhIGAojnZVSu4vMBpMP4yA",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[77]||(r[77]=[t("DeepSpeed Chat：一键搞定不同规模 ChatGPT 类模型训练！",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://hacks.mozilla.org/2023/11/introducing-llamafile/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[78]||(r[78]=[t("Introducing llamafile - Mozilla Hacks - the Web developer blog",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://github.com/Mozilla-Ocho/llamafile?utm_source=substack&utm_medium=email",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[79]||(r[79]=[t("Mozilla-Ocho/llamafile: Distribute and run LLMs with a single file.",-1)])]),_:1})]),r[156]||(r[156]=v("",17)),e("p",null,[l(n,{href:"https://github.com/OpenBMB/XAgent",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[80]||(r[80]=[t("https://github.com/OpenBMB/XAgent",-1)])]),_:1})]),r[157]||(r[157]=e("p",null,"Prompt flow 开源，支持在 vscode 中流式可视化编辑和开发 GPT Agent，方便为 LLM 应用解决原型构建，基准测试，以及生产落地和监控。",-1)),r[158]||(r[158]=e("p",null,"microsoft/promptflow: Build high-quality LLM apps - from prototyping, testing to production deployment and monitoring.",-1)),e("p",null,[l(n,{href:"https://github.com/microsoft/promptflow",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[81]||(r[81]=[t("https://github.com/microsoft/promptflow",-1)])]),_:1})]),e("p",null,[r[83]||(r[83]=t("AutoGen 开源，是 ",-1)),l(n,{href:"https://github.com/microsoft/FLAML%EF%BC%88",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[82]||(r[82]=[t("https://github.com/microsoft/FLAML（",-1)])]),_:1}),r[84]||(r[84]=t(" 自动机器学习和全自动微调框架 ）的衍生品，相比 AutoGPT 而言，这个项目旨在提供更多的多 agent 协作的工具，可以理解为 langchain multi agent 的平替，也可以理解为可以用 AutoGen 可以配合 Prompt flow 拼出一个 XAgent",-1))]),e("p",null,[r[86]||(r[86]=t("microsoft/autogen: Enable Next-Gen Large Language Model Applications. Join our Discord: ",-1)),l(n,{href:"https://discord.gg/pAbnFJrkgZ",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[85]||(r[85]=[t("https://discord.gg/pAbnFJrkgZ",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://github.com/microsoft/autogen",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[87]||(r[87]=[t("https://github.com/microsoft/autogen",-1)])]),_:1})]),r[159]||(r[159]=e("p",null,"看 NVIDIA 发了研究 Blog 说自己用类似于 XAgent 外循环 + 内循环的方式去让小模型和数字孪生能够对「对用人手进行转笔这样的动作进行建模」这样的复杂任务进行微调和监督，实现更全面和智能的无监督学习。",-1)),e("p",null,[l(n,{href:"https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[88]||(r[88]=[t("https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/",-1)])]),_:1})]),r[160]||(r[160]=e("p",null,"在 Minecraft 中玩游戏",-1)),e("p",null,[r[90]||(r[90]=t("MineDojo/Voyager: An Open-Ended Embodied Agent with Large Language Models ",-1)),l(n,{href:"https://github.com/MineDojo/Voyager",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[89]||(r[89]=[t("https://github.com/MineDojo/Voyager",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://arxiv.org/abs/2305.16291",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[91]||(r[91]=[t("arXiv [2305.16291] Voyager: An Open-Ended Embodied Agent with Large Language Models",-1)])]),_:1})]),e("p",null,[r[93]||(r[93]=t("Voyager | An Open-Ended Embodied Agent with Large Language Models ",-1)),l(n,{href:"https://voyager.minedojo.org/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[92]||(r[92]=[t("https://voyager.minedojo.org/",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.cnbeta.com.tw/articles/tech/1396051.htm",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[94]||(r[94]=[t("新型人工智能算法可在5秒钟内从2D图像中创建3D模型 - VR / AR / 3D / IMAX - cnBeta.COM",-1)])]),_:1})]),e("p",null,[r[96]||(r[96]=t("Frameworks for Serving LLMs. A comprehensive guide into LLMs inference and serving | by Sergei Savvov | Jul, 2023 | Medium | Better Programming ",-1)),l(n,{href:"https://betterprogramming.pub/frameworks-for-serving-llms-60b7f7b23407",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[95]||(r[95]=[t("https://betterprogramming.pub/frameworks-for-serving-llms-60b7f7b23407",-1)])]),_:1})]),e("blockquote",null,[e("p",null,[r[99]||(r[99]=t('X 上的 fin：“这是一篇打破GPT“涌现”概念神话的论文，终于说出了我一直以来的一个直觉，这才是比较符合事物发展规律的 一句话总结，所谓GPT“涌现”能力，是因为人为修改了“达标”的评价标准，给人"涌现"的错觉 一旦使用更合理的评价指标，就会发现GPT能力值随着模型增大是线性增长的，从评价指标上直接解构了“涌现”… ',-1)),l(n,{href:"https://t.co/NJv7jCjM4h%E2%80%9D",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[97]||(r[97]=[t("https://t.co/NJv7jCjM4h”",-1)])]),_:1}),r[100]||(r[100]=t(" / X ",-1)),l(n,{href:"https://twitter.com/fi56622380/status/1654386086746132481",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[98]||(r[98]=[t("https://twitter.com/fi56622380/status/1654386086746132481",-1)])]),_:1})])]),e("p",null,[r[102]||(r[102]=t("Nature：DeepMind大模型突破60年数学难题 解法超出人类已有认知 - AI 人工智能 - cnBeta.COM ",-1)),l(n,{href:"https://www.cnbeta.com.tw/articles/tech/1404741.htm",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[101]||(r[101]=[t("https://www.cnbeta.com.tw/articles/tech/1404741.htm",-1)])]),_:1})]),r[161]||(r[161]=e("h2",{id:"参考资料",tabindex:"-1"},[t("参考资料 "),e("a",{class:"header-anchor",href:"#参考资料","aria-label":"Permalink to “参考资料”"},"​")],-1)),e("p",null,[l(n,{href:"https://gist.github.com/rain-1/eebd5e5eb2784feecf450324e3341c8d",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[103]||(r[103]=[t("LLM Introduction: Learn Language Models",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://typefully.com/DanHollick/how-chatgpt-works-a-deep-dive-yA3ppZC",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[104]||(r[104]=[t("How ChatGPT works: a deep dive | Dan Hollick",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.ted.com/talks/greg_brockman_the_inside_story_of_chatgpt_s_astonishing_potential",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[105]||(r[105]=[t("Greg Brockman: The inside story of ChatGPT's astonishing potential | TED Talk",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://txt.cohere.com/what-are-transformer-models/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[106]||(r[106]=[t("What Are Transformer Models and How Do They Work?",-1)])]),_:1})]),e("p",null,[l(n,{href:"http://hemin.live/archives/1143",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[107]||(r[107]=[t("面向完全外行的chatGPT和大语言模型的介绍 – From nothing",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://magazine.sebastianraschka.com/p/understanding-large-language-models?utm_source=direct&utm_campaign=post&utm_medium=web",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[108]||(r[108]=[t("Understanding Large Language Models",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.bilibili.com/video/BV1uu4y1m7ak",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[109]||(r[109]=[t("关于 AI 的深度研究：ChatGPT 正在产生心智吗？",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.bilibili.com/video/BV1MY4y1R7EN/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[110]||(r[110]=[t("【渐构】万字科普GPT4为何会颠覆现有工作流；为何你要关注微软Copilot、文心一言等大模型 - 哔哩哔哩 bilibili",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.bilibili.com/video/BV1VL411U7MU/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[111]||(r[111]=[t("2023年3月，人类终究走上了一条无法回头的路 - 哔哩哔哩 bilibili",-1)])]),_:1})]),e("p",null,[l(n,{href:"https://www.bilibili.com/video/BV1v3411r78R",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[112]||(r[112]=[t("强烈推荐！台大李宏毅自注意力机制和Transformer详解！- 哔哩哔哩 bilibili",-1)])]),_:1})]),r[162]||(r[162]=e("h2",{id:"延伸阅读",tabindex:"-1"},[t("延伸阅读 "),e("a",{class:"header-anchor",href:"#延伸阅读","aria-label":"Permalink to “延伸阅读”"},"​")],-1)),e("ul",null,[e("li",null,[l(n,{href:"https://blog.wtf.sg/posts/2023-02-03-the-new-xor-problem/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[113]||(r[113]=[t("when trees fall... | The New XOR Problem",-1)])]),_:1})]),e("li",null,[l(n,{href:"https://osanseviero.github.io/hackerllama/blog/posts/random_transformer/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[114]||(r[114]=[t("hackerllama - The Random Transformer",-1)])]),_:1})]),e("li",null,[l(n,{href:"https://jalammar.github.io/illustrated-transformer/",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[115]||(r[115]=[t("The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.",-1)])]),_:1})]),e("li",null,[l(n,{href:"https://levelup.gitconnected.com/understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[116]||(r[116]=[t("Solving Transformer by Hand: A Step-by-Step Math Example | by Fareed Khan | Dec, 2023 | Level Up Coding",-1)])]),_:1})]),e("li",null,[l(n,{href:"https://gist.github.com/veekaybee/be375ab33085102f9027853128dc5f0e",target:"_blank",rel:"noreferrer"},{default:f(()=>[...r[117]||(r[117]=[t("Normcore LLM Reads",-1)])]),_:1})])]),l(u),l(s)])}const O=p(z,[["render",w]]);export{M as __pageData,O as default};
