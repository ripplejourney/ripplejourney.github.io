import{_ as o,ad as l,c as d,o as g,b as t,k as a,aE as r,a5 as s,m as n}from"./chunks/framework.BN_kmrHV.js";const D=JSON.parse('{"title":"åˆ†å¸ƒå¼è®­ç»ƒ","description":"","frontmatter":{"tags":["AI","AI/æ•™ç¨‹"]},"headers":[],"relativePath":"zh-CN/ç¬”è®°/ğŸ¤– AI äººå·¥æ™ºèƒ½/ä»é›¶å¼€å§‹çš„æœºå™¨å­¦ä¹ ä¹‹æ—…/åˆ†å¸ƒå¼è®­ç»ƒ.md","filePath":"zh-CN/ç¬”è®°/ğŸ¤– AI äººå·¥æ™ºèƒ½/ä»é›¶å¼€å§‹çš„æœºå™¨å­¦ä¹ ä¹‹æ—…/åˆ†å¸ƒå¼è®­ç»ƒ.md"}'),u={name:"zh-CN/ç¬”è®°/ğŸ¤– AI äººå·¥æ™ºèƒ½/ä»é›¶å¼€å§‹çš„æœºå™¨å­¦ä¹ ä¹‹æ—…/åˆ†å¸ƒå¼è®­ç»ƒ.md"},y={class:"footnotes"},F={class:"footnotes-list"},f={id:"fn1",class:"footnote-item"};function b(A,i,C,m,c,B){const h=l("NolebasePageProperties"),e=l("VPNolebaseInlineLinkPreview"),p=l("NolebaseGitContributors"),k=l("NolebaseGitChangelog");return g(),d("div",null,[i[46]||(i[46]=t("h1",{id:"åˆ†å¸ƒå¼è®­ç»ƒ",tabindex:"-1"},[s("åˆ†å¸ƒå¼è®­ç»ƒ "),t("a",{class:"header-anchor",href:"#åˆ†å¸ƒå¼è®­ç»ƒ","aria-label":"Permalink to â€œåˆ†å¸ƒå¼è®­ç»ƒâ€"},"â€‹")],-1)),a(h),i[47]||(i[47]=r('<p>ç°åœ¨å·²ç»ä¸æ¨èä½¿ç”¨ <code>DataParallel</code> äº†<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>ï¼Œ</p><p><code>rank</code></p><p><code>gpu</code></p><p><code>local_rank</code>ï¼šè¿›ç¨‹é˜¶åºï¼ˆrankï¼‰</p><p><code>global_rank</code></p><p><code>world_size</code>ï¼šæ€»è¿›ç¨‹æ•°</p><p><code>torchrun</code></p><p><code>torch.distributed.launch</code></p><p><code>nproc_per_node</code></p><h2 id="ä»€ä¹ˆæ˜¯-ddp" tabindex="-1">ä»€ä¹ˆæ˜¯ DDPï¼Ÿ <a class="header-anchor" href="#ä»€ä¹ˆæ˜¯-ddp" aria-label="Permalink to â€œä»€ä¹ˆæ˜¯ DDPï¼Ÿâ€">â€‹</a></h2><p><code>DistributedDataParallel</code></p><p><code>NCCL</code></p><p><code>RDMA</code></p><p><code>NVML</code></p><p><code>torch.distributed</code></p><p>åˆ†å¸ƒå¼è®¡ç®—</p><p>All-Reduce</p><p>Reduced ring</p>',18)),t("blockquote",null,[t("p",null,[i[1]||(i[1]=s("In CPython, theÂ ",-1)),i[2]||(i[2]=t("strong",null,"global interpreter lock",-1)),i[3]||(i[3]=s(", orÂ ",-1)),i[4]||(i[4]=t("strong",null,"GIL",-1)),i[5]||(i[5]=s(", is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes at once. The GIL prevents race conditions and ensures thread safety. A nice explanation ofÂ ",-1)),a(e,{href:"https://python.land/python-concurrency/the-python-gil",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[0]||(i[0]=[s("how the Python GIL helps in these areas can be found here",-1)])]),_:1}),i[6]||(i[6]=s(". In short, this mutex is necessary mainly because CPython's memory management is not thread-safe.",-1))]),t("p",null,[i[8]||(i[8]=s("æ¥æºï¼š ",-1)),a(e,{href:"https://wiki.python.org/moin/GlobalInterpreterLock",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[7]||(i[7]=[s("GlobalInterpreterLock - Python Wiki",-1)])]),_:1})])]),t("p",null,[i[10]||(i[10]=s("Distributed training with ğŸ¤— Accelerate ",-1)),a(e,{href:"https://huggingface.co/docs/transformers/accelerate",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[9]||(i[9]=[s("https://huggingface.co/docs/transformers/accelerate",-1)])]),_:1})]),t("p",null,[a(e,{href:"https://pytorch.org/torchx/latest/",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[11]||(i[11]=[s("TorchX â€” PyTorch/TorchX main documentation",-1)])]),_:1})]),t("p",null,[a(e,{href:"https://github.com/pytorch/torchx",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[12]||(i[12]=[s("pytorch/torchx: TorchX is a universal job launcher for PyTorch applications. TorchX is designed to have fast iteration time for training/research and support for E2E production ML pipelines when you're ready.",-1)])]),_:1})]),t("p",null,[a(e,{href:"https://pytorch.org/docs/stable/elastic/kubernetes.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[13]||(i[13]=[s("TorchElastic Kubernetes â€” PyTorch 2.1 documentation",-1)])]),_:1})]),i[48]||(i[48]=r(`<div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light one-dark-pro" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">Initializing</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> distributed:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> GLOBAL_RANK:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> 0,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> MEMBER:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> 1/3</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">----------------------------------------------------------------------------------------------------</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">distributed_backend</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">nccl</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">All</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> distributed</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> processes</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> registered.</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> Starting</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> with</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> processes</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">----------------------------------------------------------------------------------------------------</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">LOCAL_RANK:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> -</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> CUDA_VISIBLE_DEVICES:</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [0]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">  |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Name</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">     |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Type</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">    |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Params</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">-------------------------------------</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">0</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> conv1</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">    |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Conv2d</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">  |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> 320</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> conv2</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">    |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Conv2d</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">  |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> 18.5</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> K</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">2</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> dropout1</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Dropout</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> 0</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">3</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> dropout2</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Dropout</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> 0</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">4</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> fc1</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">      |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Linear</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">  |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> 1.2</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> M</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> fc2</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">      |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> Linear</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">  |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> 1.3</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> K</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">-------------------------------------</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">1.2</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> M</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">     Trainable</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> params</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">0</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">         Non-trainable</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> params</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">1.2</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> M</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">     Total</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> params</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">4.800</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">     Total</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> estimated</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> params</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> (MB)</span></span></code></pre></div><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light one-dark-pro" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">Initializing</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> distributed:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> GLOBAL_RANK:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> 1,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> MEMBER:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> 2/3</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">LOCAL_RANK:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> -</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> CUDA_VISIBLE_DEVICES:</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [0]</span></span></code></pre></div><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light one-dark-pro" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">Initializing</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> distributed:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> GLOBAL_RANK:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> 2,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> MEMBER:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> 3/3</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">LOCAL_RANK:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> -</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> CUDA_VISIBLE_DEVICES:</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [0]</span></span></code></pre></div><p>Pytorch DDP</p>`,4)),t("p",null,[a(e,{href:"https://pytorch.org/tutorials/intermediate/ddp_tutorial.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[14]||(i[14]=[s("Getting Started with Distributed Data Parallel â€” PyTorch Tutorials 2.2.0+cu121 documentation",-1)])]),_:1}),a(e,{href:"https://pytorch.org/tutorials/intermediate/dist_tuto.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[15]||(i[15]=[s("Writing Distributed Applications with PyTorch â€” PyTorch Tutorials 2.2.0+cu121 documentation",-1)])]),_:1}),a(e,{href:"https://pytorch.org/tutorials/beginner/saving_loading_models.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[16]||(i[16]=[s("Saving and Loading Models â€” PyTorch Tutorials 2.2.0+cu121 documentation",-1)])]),_:1}),a(e,{href:"https://pytorch.org/docs/stable/distributed.elastic.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[17]||(i[17]=[s("Torch Distributed Elastic â€” PyTorch 2.1 documentation",-1)])]),_:1}),a(e,{href:"https://pytorch.org/docs/stable/elastic/kubernetes.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[18]||(i[18]=[s("TorchElastic Kubernetes â€” PyTorch 2.1 documentation",-1)])]),_:1}),a(e,{href:"https://github.com/pytorch/elastic/tree/master/kubernetes",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[19]||(i[19]=[s("elastic/kubernetes at master Â· pytorch/elastic (github.com)",-1)])]),_:1}),a(e,{href:"https://pytorch.org/torchx/latest/pipelines/kfp.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[20]||(i[20]=[s("Kubeflow Pipelines â€” PyTorch/TorchX main documentation",-1)])]),_:1}),a(e,{href:"https://pytorch.org/torchx/latest/",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[21]||(i[21]=[s("TorchX â€” PyTorch/TorchX main documentation",-1)])]),_:1}),a(e,{href:"https://pytorch.org/torchx/latest/pipelines/kfp.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[22]||(i[22]=[s("Kubeflow Pipelines â€” PyTorch/TorchX main documentation",-1)])]),_:1})]),i[49]||(i[49]=t("p",null,"ç›‘æ§ Pytorch",-1)),t("p",null,[a(e,{href:"https://pytorch.org/docs/stable/elastic/metrics.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[23]||(i[23]=[s("Metrics â€” PyTorch 2.1 documentation",-1)])]),_:1})]),i[50]||(i[50]=t("p",null,"Trainer",-1)),t("p",null,[a(e,{href:"https://huggingface.co/docs/transformers/accelerate",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[24]||(i[24]=[s("Distributed training with ğŸ¤— Accelerate (huggingface.co)",-1)])]),_:1})]),t("ul",null,[t("li",null,[a(e,{href:"https://zhuanlan.zhihu.com/p/489011749",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[25]||(i[25]=[s("PyTorch åˆ†å¸ƒå¼è®­ç»ƒå®ç°(DP/DDP/torchrun/å¤šæœºå¤šå¡) - çŸ¥ä¹",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://zhuanlan.zhihu.com/p/477073906",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[26]||(i[26]=[s("Pytorch - åˆ†å¸ƒå¼è®­ç»ƒæç®€ä½“éªŒ - çŸ¥ä¹",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://zhuanlan.zhihu.com/p/358974461",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[27]||(i[27]=[s("PyTorchåˆ†å¸ƒå¼è®­ç»ƒåŸºç¡€--DDPä½¿ç”¨ - çŸ¥ä¹",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://zhuanlan.zhihu.com/p/463842164",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[28]||(i[28]=[s("å¼€æºä¸€ä¸ª PyTorch åˆ†å¸ƒå¼ï¼ˆDDPï¼‰è®­ç»ƒ mnist çš„ä¾‹å­ä»£ç  - çŸ¥ä¹",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://pytorch.org/docs/stable/notes/ddp.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[29]||(i[29]=[s("Distributed Data Parallel â€” PyTorch 2.1 documentation",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://roman-kazinnik.medium.com/machine-learning-as-a-flow-kubeflow-vs-metaflow-75f65bd251ec",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[30]||(i[30]=[s("Machine Learning as a Flow: Kubeflow vs. Metaflow | by Roman Kazinnik | Medium",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://www.jianshu.com/p/8c0e7edbefb9",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[31]||(i[31]=[s("Ring Allreduce - ç®€ä¹¦",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://picture.iczhiku.com/weixin/message1570798743118.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[32]||(i[32]=[s("GPUé«˜æ•ˆé€šä¿¡ç®—æ³•â€”â€”Ring Allreduce",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://en.wikipedia.org/wiki/Reduced_ring",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[33]||(i[33]=[s("Reduced ring - Wikipedia",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://roman-kazinnik.medium.com/machine-learning-distributed-ring-reduce-vs-all-reduce-cb8e97ade42e",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[34]||(i[34]=[s("Machine Learning Distributed: Ring-Reduce vs. All-Reduce | by Roman Kazinnik | Medium",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://www.cnblogs.com/devilmaycry812839668/p/12446933.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[35]||(i[35]=[s("ã€è½¬è½½ã€‘ Ring Allreduce (æ·±åº¦ç¥ç»ç½‘ç»œçš„åˆ†å¸ƒå¼è®¡ç®—èŒƒå¼ -------------- ç¯å½¢å…¨å±€è§„çº¦) - Angry_Panda - åšå®¢å›­",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://blog.csdn.net/weixin_43850253/article/details/131706419",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[36]||(i[36]=[s("ddp å¤šå¡è®­ç»ƒtorch è®°å½•_torch ddp å¡æ­»-CSDNåšå®¢",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://zhuanlan.zhihu.com/p/159404316",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[37]||(i[37]=[s("pytorchå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒç®€è¦åˆ†æ - çŸ¥ä¹",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[38]||(i[38]=[s("Distributed data parallel training in Pytorch",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://zhuanlan.zhihu.com/p/105755472",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[39]||(i[39]=[s("Pytorchä¸­çš„Distributed Data Parallelä¸æ··åˆç²¾åº¦è®­ç»ƒï¼ˆApexï¼‰ - çŸ¥ä¹",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://medium.com/ching-i/pytorch-%E5%88%86%E6%95%A3%E5%BC%8F%E8%A8%93%E7%B7%B4-distributeddataparallel-%E5%AF%A6%E4%BD%9C%E7%AF%87-35c762cb7e08",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[40]||(i[40]=[s("Pytorch åˆ†æ•£å¼è¨“ç·´ DistributedDataParallel â€” å¯¦ä½œç¯‡ | by æè¬¦ä¼Š | è¬¦ä¼Šçš„é–±è®€ç­†è¨˜ | Medium",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://pytorch-lightning.readthedocs.io/en/1.4.9/advanced/multi_gpu.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[41]||(i[41]=[s("Multi-GPU training â€” PyTorch Lightning 1.4.9 documentation",-1)])]),_:1})]),t("li",null,[a(e,{href:"https://www.bilibili.com/video/BV1mc411y7jW/?spm_id_from=333.1007.tianma.10-4-38.click&vd_source=f0545eb2f2f0269a5a9941436ba53b7d",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[42]||(i[42]=[s("Deepspeed å¤§æ¨¡å‹åˆ†å¸ƒå¼æ¡†æ¶ç²¾è®² - å“”å“©å“”å“© bilibili",-1)])]),_:1})])]),i[51]||(i[51]=t("h2",{id:"å‚è€ƒèµ„æ–™",tabindex:"-1"},[s("å‚è€ƒèµ„æ–™ "),t("a",{class:"header-anchor",href:"#å‚è€ƒèµ„æ–™","aria-label":"Permalink to â€œå‚è€ƒèµ„æ–™â€"},"â€‹")],-1)),a(p),a(k),i[52]||(i[52]=t("hr",{class:"footnotes-sep"},null,-1)),t("section",y,[t("ol",F,[t("li",f,[t("p",null,[a(e,{href:"https://pytorch.org/tutorials/intermediate/ddp_tutorial.html",target:"_blank",rel:"noreferrer"},{default:n(()=>[...i[43]||(i[43]=[s("Getting Started with Distributed Data Parallel â€” PyTorch Tutorials 2.2.0+cu121 documentation",-1)])]),_:1}),i[44]||(i[44]=s()),i[45]||(i[45]=t("a",{href:"#fnref1",class:"footnote-backref"},"â†©ï¸",-1))])])])])])}const P=o(u,[["render",b]]);export{D as __pageData,P as default};
